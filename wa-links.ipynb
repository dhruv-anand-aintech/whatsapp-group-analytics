{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "\n",
    "chat_file_name = \"path/to/chat/WhatsApp Chat with blah.txt\"\n",
    "text = open(chat_file_name, \"r\").read()\n",
    "# extract all urls from the text into a list, along with the rest of the text (in previous line as well) in the message in a list of tuples\n",
    "\n",
    "urls = re.findall(\n",
    "    \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "    text,\n",
    ")\n",
    "# put into a dataframe\n",
    "df = pd.DataFrame({\"url\": urls})\n",
    "\n",
    "# get context of the url by finding the text between timestamp lines (4/5/23, 6:41 PM)\n",
    "# split the text into lines\n",
    "lines = text.splitlines()\n",
    "# find the indices of the lines that contain the url\n",
    "url_indices = {}\n",
    "for url in urls:\n",
    "    for i, line in enumerate(lines):\n",
    "        if url in line:\n",
    "            url_indices[url] = i\n",
    "\n",
    "\n",
    "# get the context of the url by finding the text between timestamp lines (4/5/23, 6:41 PM)\n",
    "def get_context(url):\n",
    "    # get the index of the line that contains the url\n",
    "    inp_index = url_indices[url]\n",
    "    index = inp_index\n",
    "    while index > 0:\n",
    "        index -= 1\n",
    "        # if the line contains a timestamp, then the previous line contains the context\n",
    "        if re.match(r\"\\d{1,2}\\/\\d{1,2}\\/\\d{1,2}, \\d{1,2}:\\d{1,2} [AP]M\", lines[index]):\n",
    "            # return lines from this line to the line that contains the url\n",
    "            pre_context = lines[index:inp_index]\n",
    "            break\n",
    "    # get the index of the line that contains the url\n",
    "    index = inp_index\n",
    "    while index < len(lines):\n",
    "        index += 1\n",
    "        # if the line contains a timestamp, then the next line contains the context\n",
    "        if re.match(r\"\\d{1,2}\\/\\d{1,2}\\/\\d{1,2}, \\d{1,2}:\\d{1,2} [AP]M\", lines[index]):\n",
    "            # return lines from this line to the line that contains the url\n",
    "            post_context = lines[inp_index:index]\n",
    "            break\n",
    "    return pre_context + post_context\n",
    "\n",
    "\n",
    "# get context of the url for each url in the dataframe\n",
    "df[\"context\"] = df[\"url\"].apply(get_context)\n",
    "df.to_excel(\"path/to/chat/whatsapp-links-context.xlsx\")\n",
    "# get title of the url\n",
    "\n",
    "\n",
    "def get_title(url):\n",
    "    try:\n",
    "        # get only head of the page to reduce time\n",
    "        page = requests.get(url, stream=True, timeout=5)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        title = soup.find(\"title\").text\n",
    "        return title\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# get title of the url for each url in the dataframe using apply and tqdm\n",
    "tqdm.pandas()\n",
    "df[\"title\"] = df[\"url\"].progress_apply(get_title)\n",
    "df.to_excel(\"path/to/chat/whatsapp-links-context-titles.xlsx\")\n",
    "urls = re.findall(\n",
    "    \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "    text,\n",
    ")\n",
    "# standardize the urls by converting them to lowercase and removing trailing slashes and anything after #\n",
    "urls = [url.lower().split(\"#\")[0].rstrip(\"/\") for url in urls]\n",
    "\n",
    "\n",
    "# count the number of times each url appears in the list\n",
    "url_counts = Counter(urls)\n",
    "\n",
    "# convert the url_counts dictionary into a pandas dataframe\n",
    "url_counts_df = pd.DataFrame.from_dict(url_counts, orient=\"index\").reset_index()\n",
    "url_counts_df.columns = [\"url\", \"count\"]\n",
    "\n",
    "# sort the dataframe by the count column\n",
    "url_counts_df = url_counts_df.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# print the top 10 urls with word wrap\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "url_counts_df.head(10)\n",
    "# put this in a excel file\n",
    "url_counts_df.to_excel(\"path/to/chat/links.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
